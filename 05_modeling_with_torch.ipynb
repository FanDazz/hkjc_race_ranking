{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_key</th>\n",
       "      <th>race_date</th>\n",
       "      <th>dr</th>\n",
       "      <th>distance</th>\n",
       "      <th>field_going</th>\n",
       "      <th>course_type</th>\n",
       "      <th>race_money</th>\n",
       "      <th>act_wt</th>\n",
       "      <th>declare_horse_wt</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>horse</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>is_champ</th>\n",
       "      <th>pla</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>好地至快地</td>\n",
       "      <td>草地</td>\n",
       "      <td>575000</td>\n",
       "      <td>120</td>\n",
       "      <td>1186</td>\n",
       "      <td>7.3</td>\n",
       "      <td>有情風(N139)</td>\n",
       "      <td>薛寶力</td>\n",
       "      <td>吳定強</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.37</td>\n",
       "      <td>17.430713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>好地至快地</td>\n",
       "      <td>草地</td>\n",
       "      <td>575000</td>\n",
       "      <td>132</td>\n",
       "      <td>1022</td>\n",
       "      <td>6.1</td>\n",
       "      <td>樂趣(S150)</td>\n",
       "      <td>韋達</td>\n",
       "      <td>霍利時</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.53</td>\n",
       "      <td>17.382235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>好地至快地</td>\n",
       "      <td>草地</td>\n",
       "      <td>575000</td>\n",
       "      <td>121</td>\n",
       "      <td>1085</td>\n",
       "      <td>48.0</td>\n",
       "      <td>穩佔先機(N359)</td>\n",
       "      <td>連達文</td>\n",
       "      <td>苗禮德</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>57.78</td>\n",
       "      <td>17.307027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>好地至快地</td>\n",
       "      <td>草地</td>\n",
       "      <td>575000</td>\n",
       "      <td>127</td>\n",
       "      <td>1211</td>\n",
       "      <td>7.8</td>\n",
       "      <td>上浦勇將(P285)</td>\n",
       "      <td>田泰安</td>\n",
       "      <td>徐雨石</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57.82</td>\n",
       "      <td>17.295054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>好地至快地</td>\n",
       "      <td>草地</td>\n",
       "      <td>575000</td>\n",
       "      <td>124</td>\n",
       "      <td>1088</td>\n",
       "      <td>14.0</td>\n",
       "      <td>大地王者(L251)</td>\n",
       "      <td>黎海榮</td>\n",
       "      <td>李易達</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>57.89</td>\n",
       "      <td>17.274141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_key   race_date  dr  distance field_going course_type  race_money  \\\n",
       "0  2015/04/22_1  2015/04/22   2      1000       好地至快地          草地      575000   \n",
       "1  2015/04/22_1  2015/04/22   3      1000       好地至快地          草地      575000   \n",
       "2  2015/04/22_1  2015/04/22   5      1000       好地至快地          草地      575000   \n",
       "3  2015/04/22_1  2015/04/22   7      1000       好地至快地          草地      575000   \n",
       "4  2015/04/22_1  2015/04/22   1      1000       好地至快地          草地      575000   \n",
       "\n",
       "   act_wt  declare_horse_wt  win_odds       horse jockey trainer  is_champ  \\\n",
       "0     120              1186       7.3   有情風(N139)    薛寶力     吳定強         1   \n",
       "1     132              1022       6.1    樂趣(S150)     韋達     霍利時         0   \n",
       "2     121              1085      48.0  穩佔先機(N359)    連達文     苗禮德         0   \n",
       "3     127              1211       7.8  上浦勇將(P285)    田泰安     徐雨石         0   \n",
       "4     124              1088      14.0  大地王者(L251)    黎海榮     李易達         0   \n",
       "\n",
       "   pla  finish_time      speed  \n",
       "0    1        57.37  17.430713  \n",
       "1    2        57.53  17.382235  \n",
       "2    3        57.78  17.307027  \n",
       "3    4        57.82  17.295054  \n",
       "4    5        57.89  17.274141  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "perform = pd.read_csv('./horse/data/perform_clean.csv', sep=',', encoding='utf-8')\n",
    "perform['speed'] = perform['distance']/perform['finish_time']\n",
    "perform['is_champ'] = perform['pla'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "y_cols = ['is_champ', 'pla', 'finish_time', 'speed']\n",
    "date_cols = ['race_key', 'race_date']\n",
    "\n",
    "get_x_cols = lambda x: [col for col in x if (col not in y_cols) and (col not in date_cols)]\n",
    "x_cols = get_x_cols(perform.columns)\n",
    "\n",
    "perform.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_key</th>\n",
       "      <th>race_date</th>\n",
       "      <th>dr</th>\n",
       "      <th>distance</th>\n",
       "      <th>field_going</th>\n",
       "      <th>course_type</th>\n",
       "      <th>race_money</th>\n",
       "      <th>act_wt</th>\n",
       "      <th>declare_horse_wt</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>horse</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>is_champ</th>\n",
       "      <th>pla</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575000</td>\n",
       "      <td>120</td>\n",
       "      <td>1186</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.37</td>\n",
       "      <td>17.430713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575000</td>\n",
       "      <td>132</td>\n",
       "      <td>1022</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.53</td>\n",
       "      <td>17.382235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575000</td>\n",
       "      <td>121</td>\n",
       "      <td>1085</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>57.78</td>\n",
       "      <td>17.307027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575000</td>\n",
       "      <td>127</td>\n",
       "      <td>1211</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57.82</td>\n",
       "      <td>17.295054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575000</td>\n",
       "      <td>124</td>\n",
       "      <td>1088</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>57.89</td>\n",
       "      <td>17.274141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_key   race_date  dr  distance  field_going  course_type  \\\n",
       "0  2015/04/22_1  2015/04/22   2      1000            0            1   \n",
       "1  2015/04/22_1  2015/04/22   3      1000            0            1   \n",
       "2  2015/04/22_1  2015/04/22   5      1000            0            1   \n",
       "3  2015/04/22_1  2015/04/22   7      1000            0            1   \n",
       "4  2015/04/22_1  2015/04/22   1      1000            0            1   \n",
       "\n",
       "   race_money  act_wt  declare_horse_wt  win_odds  horse  jockey  trainer  \\\n",
       "0      575000     120              1186       7.3      0       0        0   \n",
       "1      575000     132              1022       6.1      1       1        1   \n",
       "2      575000     121              1085      48.0      2       2        2   \n",
       "3      575000     127              1211       7.8      3       3        3   \n",
       "4      575000     124              1088      14.0      4       4        4   \n",
       "\n",
       "   is_champ  pla  finish_time      speed  \n",
       "0         1    1        57.37  17.430713  \n",
       "1         0    2        57.53  17.382235  \n",
       "2         0    3        57.78  17.307027  \n",
       "3         0    4        57.82  17.295054  \n",
       "4         0    5        57.89  17.274141  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low cardinality, encoding with 0/1\n",
    "perform.course_type.unique() # '草地', '全天候跑道'; nunique=2\n",
    "perform.course_type = perform.course_type.replace({'全天候跑道':0, '草地':1})\n",
    "\n",
    "# high cardinality, encoding with embedding. \n",
    "#   Note: Emb value is in model, here only process with mapping index\n",
    "def col2ix(df_col:pd.Series):\n",
    "    \"\"\" Mapping from column's item to indecies.\n",
    "\n",
    "        Returns:\n",
    "            ix2item: dict\n",
    "                with key as index, value is the hashed item\n",
    "            item2ix: dict\n",
    "                with key as item, value as its index\n",
    "    \"\"\"\n",
    "    ix = list(range(df_col.nunique()))\n",
    "    item = df_col.unique().tolist()\n",
    "\n",
    "    return dict(zip(ix, item)), dict(zip(item, ix))\n",
    "\n",
    "# mapping dict\n",
    "ix2field, field2ix = col2ix(perform['field_going'])\n",
    "ix2jockey, jockey2ix = col2ix(perform['jockey'])\n",
    "ix2horse, horse2ix = col2ix(perform['horse'])\n",
    "ix2trainer, trainer2ix = col2ix(perform['trainer'])\n",
    "\n",
    "# perform after mapping\n",
    "perform['field_going'] = perform['field_going'].apply(lambda x: field2ix[x])\n",
    "perform['jockey'] = perform['jockey'].apply(lambda x: jockey2ix[x])\n",
    "perform['horse'] = perform['horse'].apply(lambda x: horse2ix[x])\n",
    "perform['trainer'] = perform['trainer'].apply(lambda x: trainer2ix[x])\n",
    "\n",
    "\n",
    "perform.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_key</th>\n",
       "      <th>race_date</th>\n",
       "      <th>dr</th>\n",
       "      <th>distance</th>\n",
       "      <th>field_going</th>\n",
       "      <th>course_type</th>\n",
       "      <th>race_money</th>\n",
       "      <th>act_wt</th>\n",
       "      <th>declare_horse_wt</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>horse</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>is_champ</th>\n",
       "      <th>pla</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.404898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394974</td>\n",
       "      <td>-0.540745</td>\n",
       "      <td>1.080522</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.37</td>\n",
       "      <td>17.430713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.404898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394974</td>\n",
       "      <td>1.432011</td>\n",
       "      <td>-1.417146</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.53</td>\n",
       "      <td>17.382235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.404898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394974</td>\n",
       "      <td>-0.376349</td>\n",
       "      <td>-0.457676</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>57.78</td>\n",
       "      <td>17.307027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.404898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394974</td>\n",
       "      <td>0.610030</td>\n",
       "      <td>1.461264</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57.82</td>\n",
       "      <td>17.295054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/04/22_1</td>\n",
       "      <td>2015/04/22</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.404898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394974</td>\n",
       "      <td>0.116841</td>\n",
       "      <td>-0.411987</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>57.89</td>\n",
       "      <td>17.274141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_key   race_date  dr  distance  field_going  course_type  \\\n",
       "0  2015/04/22_1  2015/04/22   2 -1.404898            0            1   \n",
       "1  2015/04/22_1  2015/04/22   3 -1.404898            0            1   \n",
       "2  2015/04/22_1  2015/04/22   5 -1.404898            0            1   \n",
       "3  2015/04/22_1  2015/04/22   7 -1.404898            0            1   \n",
       "4  2015/04/22_1  2015/04/22   1 -1.404898            0            1   \n",
       "\n",
       "   race_money    act_wt  declare_horse_wt  win_odds  horse  jockey  trainer  \\\n",
       "0   -0.394974 -0.540745          1.080522       7.3      0       0        0   \n",
       "1   -0.394974  1.432011         -1.417146       6.1      1       1        1   \n",
       "2   -0.394974 -0.376349         -0.457676      48.0      2       2        2   \n",
       "3   -0.394974  0.610030          1.461264       7.8      3       3        3   \n",
       "4   -0.394974  0.116841         -0.411987      14.0      4       4        4   \n",
       "\n",
       "   is_champ  pla  finish_time      speed  \n",
       "0         1    1        57.37  17.430713  \n",
       "1         0    2        57.53  17.382235  \n",
       "2         0    3        57.78  17.307027  \n",
       "3         0    4        57.82  17.295054  \n",
       "4         0    5        57.89  17.274141  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zscore_standarlization(col):\n",
    "    return (col-col.mean())/col.std()\n",
    "\n",
    "perform['distance'] = zscore_standarlization(perform['distance'])\n",
    "perform['race_money'] = zscore_standarlization(perform['race_money'])\n",
    "perform['act_wt'] = zscore_standarlization(perform['act_wt'])\n",
    "perform['declare_horse_wt'] = zscore_standarlization(perform['declare_horse_wt'])\n",
    "\n",
    "perform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform.distance.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54436, 17), (25048, 17), (23667, 17), (5721, 17))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from horse.process import train_test_split\n",
    "\n",
    "perform_train, perform_test = train_test_split(perform, 'race_date', 0.1)\n",
    "perform_train, perform_val = train_test_split(perform_train, 'race_date', 0.5)\n",
    "\n",
    "perform.shape, perform_train.shape, perform_val.shape, perform_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "y_col = ['is_champ']\n",
    "numerical_cols = ['distance', 'course_type', 'race_money', 'act_wt', 'declare_horse_wt', 'dr']\n",
    "categ_cols = ['field_going', 'horse', 'jockey', 'trainer']\n",
    "x_cols = numerical_cols + categ_cols\n",
    "\n",
    "def get_feats(data, numerical_cols, y_col):\n",
    "    num = FloatTensor(data[numerical_cols].values)\n",
    "    f = LongTensor(data['field_going'].values)\n",
    "    j = LongTensor(data['jockey'].values)\n",
    "    h = LongTensor(data['horse'].values)\n",
    "    t = LongTensor(data['trainer'].values)\n",
    "    y = FloatTensor(data[y_col].values)\n",
    "\n",
    "    X = (num, f, j, h, t)\n",
    "    return X, y\n",
    "\n",
    "def horse_data_loader(X, y, batch_size, shuffle):\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    return DataLoader(list(zip(*X, y)), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def create_data_batch(data, numerical_cols, y_col, batch_size, shuffle=True):\n",
    "    X, y = get_feats(data, numerical_cols, y_col)\n",
    "\n",
    "    return horse_data_loader(X, y, batch_size, shuffle)\n",
    "\n",
    "dl = create_data_batch(perform_train, numerical_cols, y_col, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from horse.process import racing_champ, AveragePrecision\n",
    "\n",
    "def prep_eval_data(perform):\n",
    "    \"\"\"\n",
    "    ((race_key, dr), (X, f, j, h, t))\n",
    "    \"\"\"\n",
    "    keys = (perform[['race_key', 'dr']])\n",
    "    X, y = get_feats(perform, numerical_cols, y_col)\n",
    "\n",
    "    return keys, X\n",
    "\n",
    "def computeAP(dataset, model, way='min'):\n",
    "    func = min if way=='min' else max\n",
    "    ground_truth = racing_champ(dataset)\n",
    "    result, X = prep_eval_data(dataset)\n",
    "    score = model(*X)\n",
    "    result['win'] = score.detach().numpy()\n",
    "    result = result.groupby(['race_key']) \\\n",
    "                .apply(lambda x: x[x['win']==func(x['win'])]) \\\n",
    "                .reset_index(drop=True)[['race_key', 'dr']]\n",
    "\n",
    "    return AveragePrecision(result, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.921s] Iter=0, train loss=0.9190000295639038\n",
      "\t [VAL] AP=0.114; [TEST] AP=0.102\n",
      "[5.913s] Iter=1, train loss=0.9129999876022339\n",
      "\t [VAL] AP=0.118; [TEST] AP=0.104\n",
      "[6.249s] Iter=2, train loss=0.9079999923706055\n",
      "\t [VAL] AP=0.118; [TEST] AP=0.106\n",
      "[6.188s] Iter=3, train loss=0.902999997138977\n",
      "\t [VAL] AP=0.118; [TEST] AP=0.106\n",
      "[5.974s] Iter=4, train loss=0.8980000019073486\n",
      "\t [VAL] AP=0.121; [TEST] AP=0.108\n",
      "[6.043s] Iter=5, train loss=0.8939999938011169\n",
      "\t [VAL] AP=0.117; [TEST] AP=0.11\n",
      "[6.089s] Iter=6, train loss=0.8889999985694885\n",
      "\t [VAL] AP=0.118; [TEST] AP=0.108\n",
      "[5.995s] Iter=7, train loss=0.8849999904632568\n",
      "\t [VAL] AP=0.119; [TEST] AP=0.11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shenghui\\Desktop\\my_repository\\hkjc_race_ranking\\05_modeling_with_torch.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Shenghui/Desktop/my_repository/hkjc_race_ranking/05_modeling_with_torch.ipynb#X14sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     loss \u001b[39m=\u001b[39m BCELoss(y_pred, y)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Shenghui/Desktop/my_repository/hkjc_race_ranking/05_modeling_with_torch.ipynb#X14sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Shenghui/Desktop/my_repository/hkjc_race_ranking/05_modeling_with_torch.ipynb#X14sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     opt\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Shenghui/Desktop/my_repository/hkjc_race_ranking/05_modeling_with_torch.ipynb#X14sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     ep_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Shenghui/Desktop/my_repository/hkjc_race_ranking/05_modeling_with_torch.ipynb#X14sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m train_loss_by_ep\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(ep_loss)))\n",
      "File \u001b[1;32me:\\python38\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[1;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\python38\\lib\\site-packages\\torch\\optim\\adamw.py:137\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[0;32m    135\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 137\u001b[0m     F\u001b[39m.\u001b[39;49madamw(params_with_grad,\n\u001b[0;32m    138\u001b[0m             grads,\n\u001b[0;32m    139\u001b[0m             exp_avgs,\n\u001b[0;32m    140\u001b[0m             exp_avg_sqs,\n\u001b[0;32m    141\u001b[0m             max_exp_avg_sqs,\n\u001b[0;32m    142\u001b[0m             state_steps,\n\u001b[0;32m    143\u001b[0m             amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    144\u001b[0m             beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    145\u001b[0m             beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    146\u001b[0m             lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    147\u001b[0m             weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    148\u001b[0m             eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32me:\\python38\\lib\\site-packages\\torch\\optim\\_functional.py:139\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m    137\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    141\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[0;32m    143\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor, LongTensor\n",
    "from torch import autograd, device\n",
    "from torch import optim\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegWEmb(nn.Module):\n",
    "    \"\"\" Simple Concat + Linear txfm for all embeddings \"\"\"\n",
    "    def __init__(self, n_num_feats, k_dim_field, k_dim_id) -> None:\n",
    "        super(LinearRegWEmb, self).__init__()\n",
    "        self.n_num_feats = n_num_feats\n",
    "        self.sigmoid = torch.sigmoid\n",
    "        # init embedding for ids\n",
    "        self.emb_field = nn.Embedding(len(field2ix), k_dim_field)\n",
    "        self.emb_jockey = nn.Embedding(len(jockey2ix), k_dim_id)\n",
    "        self.emb_horse = nn.Embedding(len(horse2ix), k_dim_id)\n",
    "        self.emb_trainer = nn.Embedding(len(trainer2ix), k_dim_id)\n",
    "        # output layer\n",
    "        out_dim = n_num_feats + k_dim_field + 3*k_dim_id\n",
    "        self.Linear = nn.Linear(out_dim, 1)\n",
    "        # init all dims\n",
    "        nn.init.normal_(self.Linear.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_field.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_jockey.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_horse.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_trainer.weight, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, x, field, jockey, horse, trainer):\n",
    "        emb_f = self.emb_field(field)\n",
    "        emb_j = self.emb_jockey(jockey)\n",
    "        emb_h = self.emb_horse(horse)\n",
    "        emb_t = self.emb_trainer(trainer)\n",
    "\n",
    "        out = self.Linear(torch.concat([x, emb_f, emb_j, emb_h, emb_t], 1))\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "class LinearRegWEmbv1(nn.Module):\n",
    "    \"\"\" Dot All Embs into 1d for scale reduction \"\"\"\n",
    "    def __init__(self, n_num_feats, k_dim_field, k_dim_id) -> None:\n",
    "        super(LinearRegWEmbv1, self).__init__()\n",
    "        self.n_num_feats = n_num_feats\n",
    "        self.sigmoid = torch.sigmoid\n",
    "        # init embedding for ids\n",
    "        self.emb_field = nn.Embedding(len(field2ix), k_dim_field)\n",
    "        self.emb_jockey = nn.Embedding(len(jockey2ix), k_dim_id)\n",
    "        self.emb_horse = nn.Embedding(len(horse2ix), k_dim_id)\n",
    "        self.emb_trainer = nn.Embedding(len(trainer2ix), k_dim_id)\n",
    "        # output layer\n",
    "        out_dim = n_num_feats + 4\n",
    "        self.Linear = nn.Linear(out_dim, 1)\n",
    "        self.Linear_field = nn.Linear(k_dim_field, 1)\n",
    "        # init all dims\n",
    "        nn.init.normal_(self.Linear.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_field.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_jockey.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_horse.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.emb_trainer.weight, mean=0, std=0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x, field, jockey, horse, trainer):\n",
    "        emb_f = self.emb_field(field)\n",
    "        emb_j = self.emb_jockey(jockey)\n",
    "        emb_h = self.emb_horse(horse)\n",
    "        emb_t = self.emb_trainer(trainer)\n",
    "        f_val = self.Linear_field(emb_f)\n",
    "        hj_val = torch.matmul(emb_h.weight, emb_j.weight.T)\n",
    "        ht_val = torch.matmul(emb_h.weight, emb_t.weight.T)\n",
    "\n",
    "        out = self.Linear(torch.concat([x, f_val, hj_val, ht_val], 1))\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "def SSE(input, target):\n",
    "    return (target-input)**2\n",
    "\n",
    "def BCELoss(input, target):\n",
    "    return nn.BCEWithLogitsLoss()(input, target)\n",
    "\n",
    "# setting\n",
    "batch_size = 12\n",
    "epochs = 30\n",
    "# model\n",
    "K_DIM_F = 4\n",
    "K_DIM_IX = 16\n",
    "# optimizer\n",
    "learning_rate = 5e-6\n",
    "weight_decay = 1e-3\n",
    "\n",
    "\n",
    "model = LinearRegWEmb(n_num_feats=len(numerical_cols), k_dim_field=K_DIM_F, k_dim_id=K_DIM_IX)\n",
    "opt = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "# data prep\n",
    "X_train, y_train = get_feats(perform_train, numerical_cols, y_col)\n",
    "X_val, y_val = get_feats(perform_val, numerical_cols, y_col)\n",
    "# Loss\n",
    "train_loss_by_ep = []\n",
    "# val_loss_by_ep = []\n",
    "# Average Percision\n",
    "val_ap_by_ep = []\n",
    "test_ap_by_ep = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    t0 = time.time()\n",
    "    ep_loss = []\n",
    "    for batch_data in horse_data_loader(X_train, y_train, batch_size, shuffle=True):\n",
    "        x, f, j, h, t, y = batch_data\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = autograd.Variable(x)\n",
    "        f = autograd.Variable(f)\n",
    "        j = autograd.Variable(j)\n",
    "        h = autograd.Variable(h)\n",
    "        t = autograd.Variable(t)\n",
    "\n",
    "        y_pred = model(x, f, j, h, t)\n",
    "        loss = BCELoss(y_pred, y)\n",
    "        loss.mean().backward()\n",
    "        opt.step()\n",
    "\n",
    "        ep_loss.append(loss.data)\n",
    "\n",
    "    train_loss_by_ep.append(np.sqrt(np.mean(ep_loss)))\n",
    "    t1 = time.time()\n",
    "\n",
    "    # compute AP\n",
    "    val_ap_by_ep.append(computeAP(perform_val, model, way='max'))\n",
    "    test_ap_by_ep.append(computeAP(perform_test, model, way='max'))\n",
    "\n",
    "    print(f'[{round(t1-t0, 3)}s] Iter={ep}, train loss={round(train_loss_by_ep[-1], 3)}')\n",
    "    print(f'\\t [VAL] AP={round(val_ap_by_ep[-1], 3)}; [TEST] AP={round(test_ap_by_ep[-1], 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08235294117647059"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from horse.process import racing_champ, AveragePrecision\n",
    "\n",
    "def prep_eval_data(perform):\n",
    "    \"\"\"\n",
    "    ((race_key, dr), (X, f, j, h, t))\n",
    "    \"\"\"\n",
    "    keys = (perform[['race_key', 'dr']])\n",
    "    X, y = get_feats(perform, numerical_cols, y_col)\n",
    "\n",
    "    return keys, X\n",
    "\n",
    "def computeAP(dataset, model, way='min'):\n",
    "    \"\"\" Efficient compute AP for deep model. \"\"\"\n",
    "    func = min if way=='min' else max\n",
    "    ground_truth = racing_champ(dataset)\n",
    "    result, X = prep_eval_data(dataset)\n",
    "    score = model(*X)\n",
    "    result['win'] = score.detach().numpy()\n",
    "    result = result.groupby(['race_key']) \\\n",
    "                .apply(lambda x: x[x['win']==func(x['win'])]) \\\n",
    "                .reset_index(drop=True)[['race_key', 'dr']]\n",
    "\n",
    "    return AveragePrecision(result, ground_truth)\n",
    "\n",
    "computeAP(perform_val, model, way='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0988235294117647"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
